{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b9f392",
   "metadata": {},
   "source": [
    "# Titanic Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8e9f1",
   "metadata": {},
   "source": [
    "Here, I will try some classifiers to see which perform the best on the training data, and whichever performs the best will be the one I use for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed66ee",
   "metadata": {},
   "source": [
    "First, I have to import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe67ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d5201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f79541",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c049c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6449dd55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30791d33",
   "metadata": {},
   "source": [
    "Well, I probably don't need PassengerId, Ticket or Name for any predictions, so let's drop those columns.\n",
    "\n",
    "I don't think Ticket, Cabin or Parch will have useful information either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e699cfd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset=dataset.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\", \"Parch\", \"SibSp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8a7e6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Sex          object\n",
       "Age         float64\n",
       "Fare        float64\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756bf1e8",
   "metadata": {},
   "source": [
    "Embarked has a few NaNs, so I will drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cca4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['Embarked'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bfb2d",
   "metadata": {},
   "source": [
    "Ok, so Survived is our y. Our numerical features are Age, Fare and Sibsp, and categorical features are Pclass, Sex and Embarked "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca4dc7",
   "metadata": {},
   "source": [
    "I will first do in this file what I am used to, and in the next file look into the pipelines. In the course, everything starts with breaking it down into X and y, so not using a data frame instead applying the objects to a numpy array, which I kinda find weird now that I think about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6189edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f491ff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 'male' 22.0 7.25 'S']\n",
      " [1 'female' 38.0 71.2833 'C']\n",
      " [3 'female' 26.0 7.925 'S']\n",
      " ...\n",
      " [3 'female' nan 23.45 'S']\n",
      " [1 'male' 26.0 30.0 'C']\n",
      " [3 'male' 32.0 7.75 'Q']]\n",
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
      " 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0\n",
      " 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1\n",
      " 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0\n",
      " 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0\n",
      " 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc2c0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputer to fill in missing numerical data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "#the missing values are np.nan, and we replace them with the 'mean' of other elements in the column\n",
    "imputer.fit(X[:, 2:4])\n",
    "X[:, 2:4] = imputer.transform(X[:, 2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e292d73",
   "metadata": {},
   "source": [
    "We have to wait to apply standard scaling until after we split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f9029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0,1,4])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b9951e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 ... 1.0 22.0 7.25]\n",
      " [1.0 0.0 0.0 ... 0.0 38.0 71.2833]\n",
      " [0.0 0.0 1.0 ... 1.0 26.0 7.925]\n",
      " ...\n",
      " [0.0 0.0 1.0 ... 1.0 28.0 23.45]\n",
      " [1.0 0.0 0.0 ... 0.0 26.0 30.0]\n",
      " [0.0 0.0 1.0 ... 0.0 32.0 7.75]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeaf631",
   "metadata": {},
   "source": [
    "# Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "569ff9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35eec38",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14afc264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, ..., 1.0, 28.0, 8.05],\n",
       "       [0.0, 0.0, 1.0, ..., 1.0, 19.0, 10.1708],\n",
       "       [0.0, 0.0, 1.0, ..., 0.0, 28.0, 7.75],\n",
       "       ...,\n",
       "       [0.0, 0.0, 1.0, ..., 0.0, 26.0, 14.4542],\n",
       "       [0.0, 1.0, 0.0, ..., 1.0, 44.0, 26.0],\n",
       "       [0.0, 0.0, 1.0, ..., 1.0, 21.0, 8.05]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "826deafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, -2:] = sc.fit_transform(X_train[:, -2:])\n",
    "X_test[:, -2:] = sc.transform(X_test[:, -2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00531a",
   "metadata": {},
   "source": [
    "# Classifier Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc31a35",
   "metadata": {},
   "source": [
    "I realized I forgot to include the \"Embarked\" column in my original code. I added it back in and now logistic regression is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c5c5924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 13]\n",
      " [22 51]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8033707865168539"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_p1= rfc.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_p1)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd9b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.02 %\n",
      "Standard Deviation: 2.45 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ea2b9",
   "metadata": {},
   "source": [
    "I think this is better than logistic regression, but let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9eb7ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90 15]\n",
      " [18 55]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8146067415730337"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logR = LogisticRegression(random_state = 0)\n",
    "logR.fit(X_train, y_train)\n",
    "y_p2= logR.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_p2)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67b2d87f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95 10]\n",
      " [26 47]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.797752808988764"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 6, metric = 'minkowski', p = 2)\n",
    "knn.fit(X_train, y_train)\n",
    "y_p3= knn.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_p3)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "509bae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[88 17]\n",
      " [22 51]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "dtc.fit(X_train, y_train)\n",
    "y_p4= dtc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_p4)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b8e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98  7]\n",
      " [25 48]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8202247191011236"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "ksvm = SVC(kernel = 'rbf', random_state = 0)\n",
    "ksvm.fit(X_train, y_train)\n",
    "y_p5= ksvm.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_p5)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef87f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93 12]\n",
      " [18 55]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8314606741573034"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'linear', random_state = 0)\n",
    "svm.fit(X_train, y_train)\n",
    "y_p5= svm.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_p5)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07a4ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84 21]\n",
      " [13 60]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8089887640449438"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_p6= nb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_p6)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_p6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69321fb0",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee70bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e812c1",
   "metadata": {},
   "source": [
    "We can see which is best using k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcf928fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Accuracy: 80.02 %\n",
      "Standard Deviation: 2.45 %\n",
      "\n",
      "LogisticRegression(random_state=0)\n",
      "Accuracy: 79.04 %\n",
      "Standard Deviation: 2.59 %\n",
      "\n",
      "KNeighborsClassifier(n_neighbors=6)\n",
      "Accuracy: 80.16 %\n",
      "Standard Deviation: 4.09 %\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
      "Accuracy: 76.22 %\n",
      "Standard Deviation: 5.00 %\n",
      "\n",
      "SVC(random_state=0)\n",
      "Accuracy: 81.71 %\n",
      "Standard Deviation: 3.47 %\n",
      "\n",
      "SVC(kernel='linear', random_state=0)\n",
      "Accuracy: 77.49 %\n",
      "Standard Deviation: 3.36 %\n",
      "\n",
      "GaussianNB()\n",
      "Accuracy: 75.95 %\n",
      "Standard Deviation: 2.97 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_list = [rfc,logR,knn,dtc,ksvm,svm,nb]\n",
    "\n",
    "for clf in cl_list:\n",
    "    print(clf)\n",
    "    accuracies = cross_val_score(estimator = clf, X = X_train, y = y_train, cv = 10)\n",
    "    print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0de9c",
   "metadata": {},
   "source": [
    "Hmmmmm, of these, KSVM with rbf is the best, but I guess I could do some parameter tweaking for logistic regression and KNN..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12773b",
   "metadata": {},
   "source": [
    "Wow, with the original pipe method, you can tweak the preprocessor settings too thats cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f9f637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {\n",
    "#    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "#    \"classifier__C\": [0.1, 1.0, 10, 100],\n",
    "#}\n",
    "\n",
    "#grid_search = GridSearchCV(logR, param_grid, cv=10)\n",
    "#grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fae724b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=0),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1.0, 10, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=0),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1.0, 10, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=0),\n",
       "             param_grid={'C': [0.1, 1.0, 10, 100]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(logR,{\"C\": [0.1, 1.0, 10, 100]}, cv=10)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a728792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "839560d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>param_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794621</td>\n",
       "      <td>0.031810</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.793192</td>\n",
       "      <td>0.023995</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.793192</td>\n",
       "      <td>0.023995</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790376</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score param_C\n",
       "0         0.794621        0.031810     0.1\n",
       "2         0.793192        0.023995      10\n",
       "3         0.793192        0.023995     100\n",
       "1         0.790376        0.025929     1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results.sort_values(\"mean_test_score\", ascending=False)\n",
    "cv_results[\n",
    "    [\n",
    "        \"mean_test_score\",\n",
    "        \"std_test_score\",\n",
    "        \"param_C\",\n",
    "    ]\n",
    "].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "001ca23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1)\n",
      "Accuracy: 79.46 %\n",
      "Standard Deviation: 3.18 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logR=LogisticRegression(C=0.1)\n",
    "print(logR)\n",
    "accuracies = cross_val_score(estimator = logR, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30732648",
   "metadata": {},
   "source": [
    "Well... it went from 79.04 to 79.46 so I guess that is a slight improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ceb1bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(rfc,{\"n_estimators\": [5, 10, 15, 20, 30]}, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b11cb355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', n_estimators=20, random_state=0)\n",
      "Accuracy: 80.73 %\n",
      "Standard Deviation: 2.63 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 0)\n",
    "print(rfc)\n",
    "accuracies = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b939df",
   "metadata": {},
   "source": [
    "Well, that still leaves KSVM with RBF as the best model so far. I thought it would be rfc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b9d1e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98  7]\n",
      " [25 48]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8202247191011236"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "ksvm = SVC(kernel = 'rbf', random_state = 0)\n",
    "ksvm.fit(X_train, y_train)\n",
    "y_p5= ksvm.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_p5)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1176525b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00508cb4",
   "metadata": {},
   "source": [
    "So... gotta export this I guess. But what is actually expected? They have an example file so lets see what that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f0bde4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4e46f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e019a075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, ..., 1.0, 0.49352544885255145,\n",
       "        -0.4244901451208124],\n",
       "       [0.0, 1.0, 0.0, ..., 1.0, 1.5568300491794511,\n",
       "        -0.10127665229686339],\n",
       "       [0.0, 0.0, 1.0, ..., 1.0, 1.4049293919898942, -0.5524279906110798],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 0.0, -0.5697791514743482, 2.6244896417658943],\n",
       "       [0.0, 0.0, 1.0, ..., 1.0, -0.5697791514743482,\n",
       "        -0.5475598981576237],\n",
       "       [0.0, 1.0, 0.0, ..., 1.0, -0.4178784942847912,\n",
       "        -0.48664658604849487]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed352d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
